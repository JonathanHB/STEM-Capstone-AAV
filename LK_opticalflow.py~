#!/usr/bin/env python
import cv2
import numpy as np
import rospy
from sensor_msgs.msg import Image
from geometry_msgs.msg import Twist
#from geometry_msgs.msg import TwistWithCovariance
from nav_msgs.msg import Odometry
from std_msgs.msg import Float32
from cv_bridge import CvBridge, CvBridgeError
from std_msgs.msg import Empty       	 # for land/takeoff/emergency
import sys
import threading
import time
import math

class Hoop_finder:

	def __init__(self):

		self.sub_image = rospy.Subscriber("/ardrone/front/image_raw", Image, self.takeimage, queue_size=1) #gets front camera raw image
		self.sub_image = rospy.Subscriber("/ardrone/odometry", Odometry, self.odometry, queue_size=1) #gets odometry data
		self.pub_image = rospy.Publisher("~detection_image", Image, queue_size=1) #publishes the image the drone sees, with contours and ellipse superimposed
		self.pub_image2 = rospy.Publisher("~detection_image2", Image, queue_size=1) #used to debug image processing
		self.pub_twist = rospy.Publisher('cmd_vel', Twist, queue_size = 1) #publishes commands to drone
		self.bridge = CvBridge()

		self.imagex = 640
		self.imagey = 360 #dimensions of the image, in pixels

		self.ctrx = int(self.imagex/2.0)
		self.ctry = int(self.imagey/2.0) #coordinates of image center, in pixels

		self.old_gray = np.zeros((self.imagey, self.imagex), dtype = "uint8") #grayscale version of previous image used to compute flow
		self.mask = np.zeros((self.imagey, self.imagex, 3), dtype = "uint8") #stores point trails

		self.p0 = [] #previous point set used to compute flow
		self.old_xdeltas1 = np.zeros((2,maxcorners), dtype = "float32")
		self.old_xdeltas2 = np.zeros((2,maxcorners), dtype = "float32")

		self.lastangles = [] #used to compute d-theta

		maxcorners = 200 #maximum number of points used

		self.rollavglength = 10 #the number of values to use for the rolling average; long arrays are less sensitive and lag more, but resist noise better
		self.rollingavgdata = np.zeros((4,100), dtype = "float32") #stores the last [rollingavglength] flow values to compute mean
		self.v = [] #horizontal velocity from bottom camera

		#initializes the tracking array for regenerated points
		self.movedpts = np.zeros((maxcorners,2), dtype = "uint8")

		# Create some random colors for each trail
		self.color = np.random.randint(0,255,(maxcorners,3))
		# Parameters for lucas kanade optical flow, used repeatedly
		self.lk_params = dict(winSize  = (15,15),maxLevel = 2,criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))
		# params for ShiTomasi corner detection
		self.feature_params = dict(maxCorners = maxcorners,qualityLevel = 0.1,minDistance = 7,blockSize = 7)

		self.initframe = True #used to initialize point set once on the first camera frame	
		self.delta_init = True

		self.flow = [] #the flow data computed by getvector


	def takeimage(self, img): #[front camera image from subscriber] runs image processing, and feeds the resulting pose data into the navigation algorithm
		if (self.initframe): #initializes points once when program starts

			self.initflow(img)
			self.initframe = False

		self.processimage2(img)
	
	
	def odometry(self, data): #[odometry from subscriber]  the odometry is itself optical flow based
		#stores odometry data to integrate with vision processing
		#print data
		#print data.twist.twist.linear.y
		self.v = [data.twist.twist.linear.x, data.twist.twist.linear.y]
		

	def update_roll_avg(self, newdata): #[x, y, radial] <-- flow values	adds a new data set to the rolling average array, and removes the oldest one
		
		for i in range(1, self.rollavglength): #shifts data

			self.rollingavgdata[0][self.rollavglength-i] = self.rollingavgdata[0][self.rollavglength-i-1]
			self.rollingavgdata[1][self.rollavglength-i] = self.rollingavgdata[1][self.rollavglength-i-1]
			self.rollingavgdata[2][self.rollavglength-i] = self.rollingavgdata[2][self.rollavglength-i-1]
			self.rollingavgdata[3][self.rollavglength-i] = self.rollingavgdata[3][self.rollavglength-i-1]

		self.rollingavgdata[0][0] = newdata[0]
		self.rollingavgdata[1][0] = newdata[1] #adds new data
		self.rollingavgdata[2][0] = newdata[2]
		self.rollingavgdata[3][0] = newdata[3]		


	def get_roll_avg(self): #returns the means of the rolling average arrays

		sums = [0,0,0,0]

		for i in range(1, self.rollavglength): #sums data

			sums[0] += self.rollingavgdata[0][i]
			sums[1] += self.rollingavgdata[1][i]
			sums[2] += self.rollingavgdata[2][i]
			sums[3] += self.rollingavgdata[3][i]

		return [sums[0]/self.rollavglength, sums[1]/self.rollavglength, sums[2]/self.rollavglength, sums[3]/self.rollavglength] #calculates and returns averages
	

	def getangles(self, points): #[points] returns an array with the x and y angles of all the points

		z = 409.581 #camera dependent constant, with dimensions of pixels

		#range = +- 38deg, the current camera model looks decent, z is computed as (pixel distance from image center)*cot(angle of that point obtained from protractor)

		angles = [[0.0]*len(points), [0.0]*len(points)]

		for i in range(0, len(points)):
			
			if self.movedpts[i][0] == 0 and self.movedpts[i][0] == 0: #omits regenerated points

				#r = np.sqrt(points[i][0][0]*points[i][0][0] + points[i][0][1]*points[i][0][1])

				angles[1][i] = np.arctan((points[i][0][1]-self.ctry)/z)
				angles[0][i] = np.arctan((points[i][0][0]-self.ctrx)/z)
				#print angles[0][i]*57 #this produces a very reasonable set of angles, so it probably works properly		
		return angles				
	

	def getdeltas(self, angles1, angles2): #[old angles, new angles] returns an array of the change in angle of each point

		d_angles = np.zeros((2,200), dtype = "float32")

		for i in range(0, len(self.p0)):
			
			if self.movedpts[i][0] == 0 and self.movedpts[i][0] == 0: #omits regenerated points

				d_angles[0][i] = angles2[0][i] - angles1[0][i]
				d_angles[1][i] = angles2[1][i] - angles1[1][i]
				#print d_angles[0][i] #yields sane results

		return d_angles


	def wallratio(self, points, angles, deltas): #computes the ratio of distances to the two walls, assuming the drone is parallel to them and not moving laterally or turning

		rightsum = 0
		leftsum = 0

		rnum = 0
		lnum = 0

		c1 = 0.0
		c2 = 0.0

		for i in range(0, len(points)):
			
			if self.movedpts[i][0] == 0 and self.movedpts[i][0] == 0: #omits regenerated points

				#smoothdelta = (deltas[0][i] + deltas1[0][i] + deltas2[0][i])/3 #this system failed

				if abs(angles[0][i]) > .15 and deltas[0][i] != 0:
				
					val = (np.sin(angles[0][i])*abs(np.sin(angles[0][i]))*deltas[0][i])
					#val = abs(deltas[0][i])
					#print np.sign(val)
					print deltas[0][i]
					c1+=1
					if val > 0:
						c2+=1
					#print "d"
				else:

					val = 0

				if angles[0][i] > 0:
					rnum+=1
					if val >= 0:
						rightsum+=val
				else:
					lnum+=1
					if val >= 0:
						leftsum+=val
 
		#print rightsum
		#print leftsum

		#print c2/c1
		if rightsum != 0 and lnum != 0 and leftsum != 0:

			return (rnum*rnum/rightsum)/(lnum*lnum/leftsum) #returns distance ratio

		print "bad data"
		return 0 #I should use -1 and have a proper response to it, since 0 is a possible ratio without either count being 0
	

	def walldelta(self, angles1, angles2):

		rightsum = 0
		leftsum = 0

		rnum = 0
		lnum = 0

		output = np.zeros((200), dtype = "float32")

		for i in range(0, len(points)):
			
			if self.movedpts[i][0] == 0 and self.movedpts[i][0] == 0: #omits regenerated points

				val = (np.cotan(angles1[0][i])-1)/np.cotan(angles1[1][i])
				output[i] = val

				if angles1[0][i] > 0:
					rnum+=1
					#if val >= 0:
					rightsum+=val
				else:
					lnum+=1
					#if val >= 0:
					leftsum+=val

		return val, abs(rightsum)-abs(leftsum)


	def getvector(self, points1, points2): #[old point positions, new point positions, indices of regenerated points] obtains the average x, y, and radial in/out motion of points

		totalx = 0 #turns into average x/y
		totaly = 0

		totalrad = 0 #turns into average radial motion

		pairs = 0

		for i in range(0, len(points1)):
			
			if self.movedpts[i][0] == 0 and self.movedpts[i][0] == 0: #omits regenerated points for which flow would be computed between old and new positions

				x = points2[i][0][0]-points1[i][0][0]
				y = points2[i][0][1]-points1[i][0][1]

				totalx+=x
				totaly+=y

				px = points2[i][0][0]-self.ctrx
				py = points2[i][0][1]-self.ctry

				totalrad += (x*px + y*py)/(px*px+py*py) #the raw dot product is weighted in favor of points near the edges; this is the most computationally efficient way to do it as far as I know, but idk if it is desirable, I should do some geometry to try to figure out what if any weighting is optimal

		self.flow = [totalx/len(points1), totaly/len(points1), totalrad/len(points1)] #returns average flow values

		
	def regenbadpoints(self, points, quality): #[point locations, list of points with and without flow] flags and deflags points for which flow cannot be found

		for x in range(0, len(points)): 

			if quality[x] == 1:
				
				self.movedpts[x][0] = 0

			else:

				self.movedpts[x][0] = 1


	def regenedgepoints(self, points): #[point locations] flags and deflags points which are too close to the edge

		borderwidth = 10 #how close (in pixels) points have to be to the border to be regenerated

		uppery = self.imagey-borderwidth
		upperx = self.imagex-borderwidth

		for x in range(0, len(points)):

			if points[x][0][1] > uppery or points[x][0][1] < borderwidth or points[x][0][0] > upperx or points[x][0][0] < borderwidth: #checks point position

				self.movedpts[x][1] = 1

			else:

				self.movedpts[x][1] = 0


	def regenall(self, points, gray): #[points, grayscale image used as regeneration argument] regenerates flagged points

		m = 0

		for x in range(0, len(points)): #counts how many points need regeneration

			if self.movedpts[x][0] == 1 or self.movedpts[x][1] == 1:
				
				m+=1
								
		if m != 0:

			fp3 = dict(maxCorners = m, qualityLevel = 0.1,minDistance = 7,blockSize = 7)

			newpts = cv2.goodFeaturesToTrack(gray, mask = None, **fp3) #generates a batch of as many points need regeneration

			c = 0

			l = len(newpts) 	

			for x in range(0, len(points)):

				if self.movedpts[x][0] == 1 or self.movedpts[x][1] == 1:
				
					points[x][0] = newpts[c][0] #replaces points flagged for regeneration
					c+=1
					if c==l:
						break #terminates once all new points have been used

			
		return points #returns updated point array
				
		


	def initflow(self, imgdrone1): #generates feature point array for LK optical flow
	
		#converts from drone image to bgr8 for opencv
		imgbgr = self.bridge.imgmsg_to_cv2(imgdrone1, "bgr8")
		# Creates a grayscale version of the camera image
		self.old_gray = cv2.cvtColor(imgbgr, cv2.COLOR_BGR2GRAY)
		# Take first frame and find corners in it
		self.p0 = cv2.goodFeaturesToTrack(self.old_gray, mask = None, **self.feature_params)
		# Create a mask image for drawing purposes
		self.mask = np.zeros_like(imgbgr)

	def processimage2(self, imgdrone1): #performs optical flow and point set maintainence tasks

		imgbgr = self.bridge.imgmsg_to_cv2(imgdrone1, "bgr8") #converts from drone image to bgr8 for opencv
		frame_gray = cv2.cvtColor(imgbgr, cv2.COLOR_BGR2GRAY) # Creates a grayscale version of the camera image

		# calculates optical flow, p1 is an array of the feature points in their new positions
		p1, st, err = cv2.calcOpticalFlowPyrLK(self.old_gray, frame_gray, self.p0, None, **self.lk_params)
		 
		self.getvector(self.p0, p1)
		
		angles1 = self.getangles(self.p0)
		angles2 = self.getangles(p1)
		#deltas = self.getdeltas(angles1, angles2)
		#ratio = self.wallratio(p1, angles2, deltas) #these 4 methods plus regenbadpoints collectively contribute about 1.5s of lag
		vals, ratio = walldelta(angles1, angles2)
		print ratio		
		#print np.arctan(ratio)

		
		self.regenedgepoints(p1)

		self.regenbadpoints(p1, st) #this plus the block of 4 methods above contribute 1.5s of lag

		points = self.regenall(p1, frame_gray)

		good_new = p1#[st==1]
		good_old = self.p0#[st==1]

		#draws the tracks to show point motion
    		for i,(new,old) in enumerate(zip(good_new,good_old)):
        		a,b = new.ravel()
        		c,d = old.ravel()
        		mask = cv2.line(self.mask, (a,b),(c,d), self.color[i].tolist(), 2)
        		frame = cv2.circle(imgbgr,(a,b),5,self.color[i].tolist(),-1)
    		imgout = cv2.add(imgbgr, self.mask)

		#updates the previous frame, points, and rolling average
    		self.old_gray = frame_gray.copy()
   		self.p0 = p1
		self.update_roll_avg([self.flow[0], self.flow[1], self.flow[2], np.arctan(ratio)])
		
		#print self.v

		#draws a circle onto the camera image based on flow vector for visual debugging
		flow = self.get_roll_avg()
		
		ctr = (self.ctrx+int(9*flow[0]), self.ctry+int(9*flow[1]))
		#ctr = 400,180
		color = ()
		if flow[2]>=0:
			color = (100,20,100)
		else:
			color = (100,200,100)
			#print "reverse"


		cv2.circle(imgbgr, ctr, abs(int(1000*flow[2])), color, 10)
		cv2.circle(imgbgr, (int(self.ctrx*flow[3]*4/3.14159265358979), self.ctry), 30, (100,100,50), 10)


		#print p1[5][0][1] #the zero in the middle is required because the array is nominally 3 dimensional but one dimension has 0 thickness

		imgdrone = self.bridge.cv2_to_imgmsg(imgbgr, "8UC3") #converts opencv's bgr8 back to the drone's raw_image for rviz use, converts both hsv and rgb to rviz-readable form

		self.pub_image.publish(imgdrone)

		imgdrone2 = self.bridge.cv2_to_imgmsg(imgout, "8UC3") #converts opencv's bgr8 back to the drone's raw_image for rviz use, converts both hsv and rgb to rviz-readable form

		self.pub_image2.publish(imgdrone2)


if __name__=="__main__":

	rospy.init_node('Hoop_finder')
        
	node = Hoop_finder()

	rospy.spin()


